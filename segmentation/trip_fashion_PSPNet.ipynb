{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSPNet reference: https://github.com/Vladkryvoruchko/PSPNet-Keras-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from os.path import splitext, join, isfile, isdir, basename\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json, load_model\n",
    "import tensorflow as tf\n",
    "import layers_builder as layers\n",
    "from glob import glob\n",
    "from utils import utils\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "import cv2\n",
    "import math\n",
    "# -- Fix for macos, uncomment it\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "# --\n",
    "import matplotlib.pyplot as plt\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "\n",
    "from imageio import imread\n",
    "# These are the means for the ImageNet pretrained ResNet\n",
    "DATA_MEAN = np.array([[[123.68, 116.779, 103.939]]])  # RGB order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSPNet 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(object):\n",
    "    \"\"\"Pyramid Scene Parsing Network by Hengshuang Zhao et al 2017\"\"\"\n",
    "\n",
    "    def __init__(self, nb_classes, resnet_layers, input_shape, weights):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = nb_classes\n",
    "\n",
    "        json_path = join(\"weights\", \"keras\", weights + \".json\")\n",
    "        h5_path = join(\"weights\", \"keras\", weights + \".h5\")\n",
    "        if 'pspnet' in weights:\n",
    "            if os.path.isfile(json_path) and os.path.isfile(h5_path):\n",
    "                print(\"Keras model & weights found, loading...\")\n",
    "                with CustomObjectScope({'Interp': layers.Interp}):\n",
    "                    with open(json_path) as file_handle:\n",
    "                        self.model = model_from_json(file_handle.read())\n",
    "                self.model.load_weights(h5_path)\n",
    "            else:\n",
    "                print(\"No Keras model & weights found, import from npy weights.\")\n",
    "                self.model = layers.build_pspnet(nb_classes=nb_classes,\n",
    "                                                 resnet_layers=resnet_layers,\n",
    "                                                 input_shape=self.input_shape)\n",
    "                self.set_npy_weights(weights)\n",
    "        else:\n",
    "            print('Load pre-trained weights')\n",
    "            self.model = load_model(weights)\n",
    "\n",
    "    def predict(self, img, flip_evaluation=False):\n",
    "        \"\"\"\n",
    "        Predict segementation for an image.\n",
    "        Arguments:\n",
    "            img: must be rowsxcolsx3\n",
    "        \"\"\"\n",
    "\n",
    "        if img.shape[0:2] != self.input_shape:\n",
    "            print(\n",
    "                \"Input %s not fitting for network size %s, resizing. You may want to try sliding prediction for better results.\" % (\n",
    "                img.shape[0:2], self.input_shape))\n",
    "            img = misc.imresize(img, self.input_shape)\n",
    "\n",
    "        img = img - DATA_MEAN\n",
    "        img = img[:, :, ::-1]  # RGB => BGR\n",
    "        img = img.astype('float32')\n",
    "\n",
    "        probs = self.feed_forward(img, flip_evaluation)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def predict_sliding(self, full_img, flip_evaluation):\n",
    "        \"\"\"\n",
    "        Predict on tiles of exactly the network input shape.\n",
    "        This way nothing gets squeezed.\n",
    "        \"\"\"\n",
    "        tile_size = self.input_shape\n",
    "        classes = self.num_classes\n",
    "        overlap = 1 / 3\n",
    "\n",
    "        stride = math.ceil(tile_size[0] * (1 - overlap))\n",
    "        tile_rows = max(int(math.ceil((full_img.shape[0] - tile_size[0]) / stride) + 1), 1)  # strided convolution formula\n",
    "        tile_cols = max(int(math.ceil((full_img.shape[1] - tile_size[1]) / stride) + 1), 1)\n",
    "        print(\"Need %i x %i prediction tiles @ stride %i px\" % (tile_cols, tile_rows, stride))\n",
    "        full_probs = np.zeros((full_img.shape[0], full_img.shape[1], classes))\n",
    "        count_predictions = np.zeros((full_img.shape[0], full_img.shape[1], classes))\n",
    "        tile_counter = 0\n",
    "        for row in range(tile_rows):\n",
    "            for col in range(tile_cols):\n",
    "                x1 = int(col * stride)\n",
    "                y1 = int(row * stride)\n",
    "                x2 = min(x1 + tile_size[1], full_img.shape[1])\n",
    "                y2 = min(y1 + tile_size[0], full_img.shape[0])\n",
    "                x1 = max(int(x2 - tile_size[1]), 0)  # for portrait images the x1 underflows sometimes\n",
    "                y1 = max(int(y2 - tile_size[0]), 0)  # for very few rows y1 underflows\n",
    "\n",
    "                img = full_img[y1:y2, x1:x2]\n",
    "                padded_img = self.pad_image(img, tile_size)\n",
    "                plt.imshow(padded_img)\n",
    "                plt.show()\n",
    "                tile_counter += 1\n",
    "                print(\"Predicting tile %i\" % tile_counter)\n",
    "                padded_prediction = self.predict(padded_img, flip_evaluation)\n",
    "                prediction = padded_prediction[0:img.shape[0], 0:img.shape[1], :]\n",
    "                count_predictions[y1:y2, x1:x2] += 1\n",
    "                full_probs[y1:y2, x1:x2] += prediction  # accumulate the predictions also in the overlapping regions\n",
    "\n",
    "        # average the predictions in the overlapping regions\n",
    "        full_probs /= count_predictions\n",
    "        # visualize normalization Weights\n",
    "        # plt.imshow(np.mean(count_predictions, axis=2))\n",
    "        # plt.show()\n",
    "        return full_probs\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_image(img, target_size):\n",
    "        \"\"\"Pad an image up to the target size.\"\"\"\n",
    "        rows_missing = target_size[0] - img.shape[0]\n",
    "        cols_missing = target_size[1] - img.shape[1]\n",
    "        padded_img = np.pad(img, ((0, rows_missing), (0, cols_missing), (0, 0)), 'constant')\n",
    "        return padded_img\n",
    "\n",
    "    def predict_multi_scale(self, img, flip_evaluation, sliding_evaluation, scales):\n",
    "        \"\"\"Predict an image by looking at it with different scales.\"\"\"\n",
    "\n",
    "        full_probs = np.zeros((img.shape[0], img.shape[1], self.num_classes))\n",
    "        h_ori, w_ori = img.shape[:2]\n",
    "\n",
    "        print(\"Started prediction...\")\n",
    "        for scale in scales:\n",
    "            print(\"Predicting image scaled by %f\" % scale)\n",
    "            scaled_img = misc.imresize(img, size=scale, interp=\"bilinear\")\n",
    "\n",
    "            if sliding_evaluation:\n",
    "                scaled_probs = self.predict_sliding(scaled_img, flip_evaluation)\n",
    "            else:\n",
    "                scaled_probs = self.predict(scaled_img, flip_evaluation)\n",
    "\n",
    "            # scale probs up to full size\n",
    "            # visualize_prediction(probs)\n",
    "            probs = cv2.resize(scaled_probs, (w_ori, h_ori))\n",
    "            full_probs += probs\n",
    "        full_probs /= len(scales)\n",
    "        print(\"Finished prediction...\")\n",
    "\n",
    "        return full_probs\n",
    "\n",
    "    def feed_forward(self, data, flip_evaluation=False):\n",
    "        assert data.shape == (self.input_shape[0], self.input_shape[1], 3)\n",
    "\n",
    "        if flip_evaluation:\n",
    "            print(\"Predict flipped\")\n",
    "            input_with_flipped = np.array(\n",
    "                [data, np.flip(data, axis=1)])\n",
    "            prediction_with_flipped = self.model.predict(input_with_flipped)\n",
    "            prediction = (prediction_with_flipped[\n",
    "                          0] + np.fliplr(prediction_with_flipped[1])) / 2.0\n",
    "        else:\n",
    "            prediction = self.model.predict(np.expand_dims(data, 0))[0]\n",
    "        return prediction\n",
    "\n",
    "    def set_npy_weights(self, weights_path):\n",
    "        npy_weights_path = join(\"weights\", \"npy\", weights_path + \".npy\")\n",
    "        json_path = join(\"weights\", \"keras\", weights_path + \".json\")\n",
    "        h5_path = join(\"weights\", \"keras\", weights_path + \".h5\")\n",
    "\n",
    "        print(\"Importing weights from %s\" % npy_weights_path)\n",
    "        weights = np.load(npy_weights_path, encoding='bytes').item()\n",
    "        for layer in self.model.layers:\n",
    "            print(layer.name)\n",
    "            if layer.name[:4] == 'conv' and layer.name[-2:] == 'bn':\n",
    "                mean = weights[layer.name.encode()][\n",
    "                    'mean'.encode()].reshape(-1)\n",
    "                variance = weights[layer.name.encode()][\n",
    "                    'variance'.encode()].reshape(-1)\n",
    "                scale = weights[layer.name.encode()][\n",
    "                    'scale'.encode()].reshape(-1)\n",
    "                offset = weights[layer.name.encode()][\n",
    "                    'offset'.encode()].reshape(-1)\n",
    "\n",
    "                self.model.get_layer(layer.name).set_weights(\n",
    "                    [scale, offset, mean, variance])\n",
    "\n",
    "            elif layer.name[:4] == 'conv' and not layer.name[-4:] == 'relu':\n",
    "                try:\n",
    "                    weight = weights[layer.name.encode()]['weights'.encode()]\n",
    "                    self.model.get_layer(layer.name).set_weights([weight])\n",
    "                except Exception as err:\n",
    "                    biases = weights[layer.name.encode()]['biases'.encode()]\n",
    "                    self.model.get_layer(layer.name).set_weights([weight,\n",
    "                                                                  biases])\n",
    "        print('Finished importing weights.')\n",
    "\n",
    "        print(\"Writing keras model & weights\")\n",
    "        json_string = self.model.to_json()\n",
    "        with open(json_path, 'w') as file_handle:\n",
    "            file_handle.write(json_string)\n",
    "        self.model.save_weights(h5_path)\n",
    "        print(\"Finished writing Keras model & weights\")\n",
    "\n",
    "\n",
    "class PSPNet50(PSPNet):\n",
    "    \"\"\"Build a PSPNet based on a 50-Layer ResNet.\"\"\"\n",
    "\n",
    "    def __init__(self, nb_classes, weights, input_shape):\n",
    "        PSPNet.__init__(self, nb_classes=nb_classes, resnet_layers=50,\n",
    "                        input_shape=input_shape, weights=weights)\n",
    "\n",
    "\n",
    "class PSPNet101(PSPNet):\n",
    "    \"\"\"Build a PSPNet based on a 101-Layer ResNet.\"\"\"\n",
    "\n",
    "    def __init__(self, nb_classes, weights, input_shape):\n",
    "        PSPNet.__init__(self, nb_classes=nb_classes, resnet_layers=101,\n",
    "                        input_shape=input_shape, weights=weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation( PSPNet )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = 'example_images/2090.jpg'\n",
    "images = glob(im)\n",
    "\n",
    "# GPU 사용\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4 \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# K.set_session(sess)\n",
    "\n",
    "model = 'pspnet50_ade20k'\n",
    "\n",
    "with sess.as_default():\n",
    "    pspnet = PSPNet50(nb_classes=150, input_shape=(473, 473),\n",
    "                              weights=model)\n",
    "    for i, img_path in enumerate(images):\n",
    "            print(\"Processing image {} / {}\".format(i + 1, len(images)))\n",
    "            img = imread(img_path, pilmode='RGB')\n",
    "\n",
    "            probs = pspnet.predict_multi_scale(img, flip_evaluation=True, sliding_evaluation = True,  scales=[1.0])\n",
    "\n",
    "            cm = np.argmax(probs, axis=2)\n",
    "            pm = np.max(probs, axis=2)\n",
    "\n",
    "            colored_class_image = utils.color_class_image(cm, model)\n",
    "            alpha_blended = 0.5 * colored_class_image + 0.5 * img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원본 사진에서 object의 Bounding box 도출 (OpenCV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(im)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "bbox, label, conf = cv.detect_common_objects(img)\n",
    "output_image = draw_bbox(img, bbox, label, conf)\n",
    "\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation 처리가 된 이미지에서 bbox에 해당하는 부분만 cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = cm[bbox[0][1]:bbox[0][3], bbox[0][0]:bbox[0][2]]\n",
    "unique_elements, counts_elements = np.unique(xx, return_counts=True)\n",
    "unique_elements[np.where(counts_elements==max(counts_elements))][0]\n",
    "a,b = np.where(xx == unique_elements[np.where(counts_elements==max(counts_elements))][0])\n",
    "img_crop = img[bbox[0][1]:bbox[0][3]:, bbox[0][0]:bbox[0][2]]\n",
    "img_crop[a,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange the cluster_centers of KMeans output according to frequency of each label\n",
    "def arrange_cluster_centers(clt):\n",
    "    lb_counts = Counter(clt.labels_)\n",
    "    \n",
    "    tmp_dict = {}\n",
    "    for idx, pixel in enumerate(clt.cluster_centers_):\n",
    "        tmp_dict[ lb_counts[idx] ] = pixel  # { frequency of label : color of label } mapping\n",
    "    \n",
    "    centers_aranged_dict = dict(sorted(tmp_dict.items(), reverse=True))  # arrange the dict according to key (frequency of label)\n",
    "\n",
    "    centers_aranged_arr = np.array(list(centers_aranged_dict.values()))  # pack colors into one array\n",
    "    centers_aranged_arr = centers_aranged_arr.round().astype(\"uint8\")  # tranform the type to integer\n",
    "    centers_aranged_arr = np.expand_dims(centers_aranged_arr, 0)  # add one dimension for visualization\n",
    "    return centers_aranged_arr\n",
    "\n",
    "\n",
    "expected_num_col = 5 #cluster number\n",
    "\n",
    "# Extract dominant color using KMeans\n",
    "clt = KMeans(n_clusters = expected_num_col)\n",
    "clt.fit(img_crop[a,b])\n",
    "\n",
    "\n",
    "# Visualization\n",
    "centers_aranged_arr = arrange_cluster_centers(clt)\n",
    "plt.imshow(centers_aranged_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_crop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
