{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSPNet reference: https://github.com/Vladkryvoruchko/PSPNet-Keras-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from os.path import splitext, join, isfile, isdir, basename\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json, load_model\n",
    "import tensorflow as tf\n",
    "import layers_builder as layers\n",
    "from glob import glob\n",
    "from utils import utils\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "import cv2\n",
    "import math\n",
    "# -- Fix for macos, uncomment it\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "# --\n",
    "import matplotlib.pyplot as plt\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "\n",
    "from imageio import imread\n",
    "import json\n",
    "import time\n",
    "# These are the means for the ImageNet pretrained ResNet\n",
    "DATA_MEAN = np.array([[[123.68, 116.779, 103.939]]])  # RGB order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSPNet 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(object):\n",
    "    \"\"\"Pyramid Scene Parsing Network by Hengshuang Zhao et al 2017\"\"\"\n",
    "\n",
    "    def __init__(self, nb_classes, resnet_layers, input_shape, weights):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = nb_classes\n",
    "\n",
    "        json_path = join(\"weights\", \"keras\", weights + \".json\")\n",
    "        h5_path = join(\"weights\", \"keras\", weights + \".h5\")\n",
    "        if 'pspnet' in weights:\n",
    "            if os.path.isfile(json_path) and os.path.isfile(h5_path):\n",
    "                print(\"Keras model & weights found, loading...\")\n",
    "                with CustomObjectScope({'Interp': layers.Interp}):\n",
    "                    with open(json_path) as file_handle:\n",
    "                        self.model = model_from_json(file_handle.read())\n",
    "                self.model.load_weights(h5_path)\n",
    "            else:\n",
    "                print(\"No Keras model & weights found, import from npy weights.\")\n",
    "                self.model = layers.build_pspnet(nb_classes=nb_classes,\n",
    "                                                 resnet_layers=resnet_layers,\n",
    "                                                 input_shape=self.input_shape)\n",
    "                self.set_npy_weights(weights)\n",
    "        else:\n",
    "            print('Load pre-trained weights')\n",
    "            self.model = load_model(weights)\n",
    "\n",
    "    def predict(self, img, flip_evaluation=False):\n",
    "        \"\"\"\n",
    "        Predict segementation for an image.\n",
    "        Arguments:\n",
    "            img: must be rowsxcolsx3\n",
    "        \"\"\"\n",
    "\n",
    "        if img.shape[0:2] != self.input_shape:\n",
    "            print(\n",
    "                \"Input %s not fitting for network size %s, resizing. You may want to try sliding prediction for better results.\" % (\n",
    "                img.shape[0:2], self.input_shape))\n",
    "            img = misc.imresize(img, self.input_shape)\n",
    "\n",
    "        img = img - DATA_MEAN\n",
    "        img = img[:, :, ::-1]  # RGB => BGR\n",
    "        img = img.astype('float32')\n",
    "\n",
    "        probs = self.feed_forward(img, flip_evaluation)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def predict_sliding(self, full_img, flip_evaluation):\n",
    "        \"\"\"\n",
    "        Predict on tiles of exactly the network input shape.\n",
    "        This way nothing gets squeezed.\n",
    "        \"\"\"\n",
    "        tile_size = self.input_shape\n",
    "        classes = self.num_classes\n",
    "        overlap = 1 / 3\n",
    "\n",
    "        stride = math.ceil(tile_size[0] * (1 - overlap))\n",
    "        tile_rows = max(int(math.ceil((full_img.shape[0] - tile_size[0]) / stride) + 1), 1)  # strided convolution formula\n",
    "        tile_cols = max(int(math.ceil((full_img.shape[1] - tile_size[1]) / stride) + 1), 1)\n",
    "        print(\"Need %i x %i prediction tiles @ stride %i px\" % (tile_cols, tile_rows, stride))\n",
    "        full_probs = np.zeros((full_img.shape[0], full_img.shape[1], classes))\n",
    "        count_predictions = np.zeros((full_img.shape[0], full_img.shape[1], classes))\n",
    "        tile_counter = 0\n",
    "        for row in range(tile_rows):\n",
    "            for col in range(tile_cols):\n",
    "                x1 = int(col * stride)\n",
    "                y1 = int(row * stride)\n",
    "                x2 = min(x1 + tile_size[1], full_img.shape[1])\n",
    "                y2 = min(y1 + tile_size[0], full_img.shape[0])\n",
    "                x1 = max(int(x2 - tile_size[1]), 0)  # for portrait images the x1 underflows sometimes\n",
    "                y1 = max(int(y2 - tile_size[0]), 0)  # for very few rows y1 underflows\n",
    "\n",
    "                img = full_img[y1:y2, x1:x2]\n",
    "                padded_img = self.pad_image(img, tile_size)\n",
    "#                 plt.imshow(padded_img)\n",
    "#                 plt.show()\n",
    "                tile_counter += 1\n",
    "                print(\"Predicting tile %i\" % tile_counter)\n",
    "                padded_prediction = self.predict(padded_img, flip_evaluation)\n",
    "                prediction = padded_prediction[0:img.shape[0], 0:img.shape[1], :]\n",
    "                count_predictions[y1:y2, x1:x2] += 1\n",
    "                full_probs[y1:y2, x1:x2] += prediction  # accumulate the predictions also in the overlapping regions\n",
    "\n",
    "        # average the predictions in the overlapping regions\n",
    "        full_probs /= count_predictions\n",
    "        # visualize normalization Weights\n",
    "        # plt.imshow(np.mean(count_predictions, axis=2))\n",
    "        # plt.show()\n",
    "        return full_probs\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_image(img, target_size):\n",
    "        \"\"\"Pad an image up to the target size.\"\"\"\n",
    "        rows_missing = target_size[0] - img.shape[0]\n",
    "        cols_missing = target_size[1] - img.shape[1]\n",
    "        padded_img = np.pad(img, ((0, rows_missing), (0, cols_missing), (0, 0)), 'constant')\n",
    "        return padded_img\n",
    "\n",
    "    def predict_multi_scale(self, img, flip_evaluation, sliding_evaluation, scales):\n",
    "        \"\"\"Predict an image by looking at it with different scales.\"\"\"\n",
    "\n",
    "        full_probs = np.zeros((img.shape[0], img.shape[1], self.num_classes))\n",
    "        h_ori, w_ori = img.shape[:2]\n",
    "\n",
    "        print(\"Started prediction...\")\n",
    "        for scale in scales:\n",
    "            print(\"Predicting image scaled by %f\" % scale)\n",
    "            scaled_img = misc.imresize(img, size=scale, interp=\"bilinear\")\n",
    "\n",
    "            if sliding_evaluation:\n",
    "                scaled_probs = self.predict_sliding(scaled_img, flip_evaluation)\n",
    "            else:\n",
    "                scaled_probs = self.predict(scaled_img, flip_evaluation)\n",
    "\n",
    "            # scale probs up to full size\n",
    "            # visualize_prediction(probs)\n",
    "            probs = cv2.resize(scaled_probs, (w_ori, h_ori))\n",
    "            full_probs += probs\n",
    "        full_probs /= len(scales)\n",
    "        print(\"Finished prediction...\")\n",
    "\n",
    "        return full_probs\n",
    "\n",
    "    def feed_forward(self, data, flip_evaluation=False):\n",
    "        assert data.shape == (self.input_shape[0], self.input_shape[1], 3)\n",
    "\n",
    "        if flip_evaluation:\n",
    "            print(\"Predict flipped\")\n",
    "            input_with_flipped = np.array(\n",
    "                [data, np.flip(data, axis=1)])\n",
    "            prediction_with_flipped = self.model.predict(input_with_flipped)\n",
    "            prediction = (prediction_with_flipped[\n",
    "                          0] + np.fliplr(prediction_with_flipped[1])) / 2.0\n",
    "        else:\n",
    "            prediction = self.model.predict(np.expand_dims(data, 0))[0]\n",
    "        return prediction\n",
    "\n",
    "    def set_npy_weights(self, weights_path):\n",
    "        npy_weights_path = join(\"weights\", \"npy\", weights_path + \".npy\")\n",
    "        json_path = join(\"weights\", \"keras\", weights_path + \".json\")\n",
    "        h5_path = join(\"weights\", \"keras\", weights_path + \".h5\")\n",
    "\n",
    "        print(\"Importing weights from %s\" % npy_weights_path)\n",
    "        weights = np.load(npy_weights_path, encoding='bytes').item()\n",
    "        for layer in self.model.layers:\n",
    "            print(layer.name)\n",
    "            if layer.name[:4] == 'conv' and layer.name[-2:] == 'bn':\n",
    "                mean = weights[layer.name.encode()][\n",
    "                    'mean'.encode()].reshape(-1)\n",
    "                variance = weights[layer.name.encode()][\n",
    "                    'variance'.encode()].reshape(-1)\n",
    "                scale = weights[layer.name.encode()][\n",
    "                    'scale'.encode()].reshape(-1)\n",
    "                offset = weights[layer.name.encode()][\n",
    "                    'offset'.encode()].reshape(-1)\n",
    "\n",
    "                self.model.get_layer(layer.name).set_weights(\n",
    "                    [scale, offset, mean, variance])\n",
    "\n",
    "            elif layer.name[:4] == 'conv' and not layer.name[-4:] == 'relu':\n",
    "                try:\n",
    "                    weight = weights[layer.name.encode()]['weights'.encode()]\n",
    "                    self.model.get_layer(layer.name).set_weights([weight])\n",
    "                except Exception as err:\n",
    "                    biases = weights[layer.name.encode()]['biases'.encode()]\n",
    "                    self.model.get_layer(layer.name).set_weights([weight,\n",
    "                                                                  biases])\n",
    "        print('Finished importing weights.')\n",
    "\n",
    "        print(\"Writing keras model & weights\")\n",
    "        json_string = self.model.to_json()\n",
    "        with open(json_path, 'w') as file_handle:\n",
    "            file_handle.write(json_string)\n",
    "        self.model.save_weights(h5_path)\n",
    "        print(\"Finished writing Keras model & weights\")\n",
    "\n",
    "\n",
    "class PSPNet50(PSPNet):\n",
    "    \"\"\"Build a PSPNet based on a 50-Layer ResNet.\"\"\"\n",
    "\n",
    "    def __init__(self, nb_classes, weights, input_shape):\n",
    "        PSPNet.__init__(self, nb_classes=nb_classes, resnet_layers=50,\n",
    "                        input_shape=input_shape, weights=weights)\n",
    "\n",
    "\n",
    "class PSPNet101(PSPNet):\n",
    "    \"\"\"Build a PSPNet based on a 101-Layer ResNet.\"\"\"\n",
    "\n",
    "    def __init__(self, nb_classes, weights, input_shape):\n",
    "        PSPNet.__init__(self, nb_classes=nb_classes, resnet_layers=101,\n",
    "                        input_shape=input_shape, weights=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_person(img, i, file_path):\n",
    "    img = cv2.imread(file_path)\n",
    "    bbox, label, conf = cv.detect_common_objects(img)\n",
    "\n",
    "    if label.count('person') > 1:   # Exceptional case : 2 or more persons are detected\n",
    "        msg = '>>> Warning : More than 1 person is detected from the given picture!\\n' +\\\n",
    "              '>>> Warning in {} file : {}\\n'.format(i+1 , file_path.split('/')[-1])\n",
    "        print(msg)\n",
    "#         self.log_list_.append(msg)\n",
    "\n",
    "        area = [ (box[2]-box[0])*(box[3]-box[1]) for box in bbox ]\n",
    "        arranged_list = [ (area[idx], bbox[idx], label[idx], conf[idx]) for idx in range(len(label)) if label[idx]=='person' ]\n",
    "        arranged_list.sort(reverse=True)\n",
    "\n",
    "        bbox = [ tup[1] for tup in arranged_list  ]\n",
    "        label = [ tup[2] for tup in arranged_list  ]\n",
    "        conf = [ tup[3] for tup in arranged_list  ]\n",
    "\n",
    "    elif label.count('person') == 1:   # Ideal case : only one main preson is detected\n",
    "        idx = label.index('person')\n",
    "        bbox = [bbox[idx]]\n",
    "        label = [label[idx]]\n",
    "        conf = [conf[idx]]\n",
    "\n",
    "    else:   # Exceptional case : No person is detected\n",
    "        msg = '>>> Error : No person is detected from the given picture!'\n",
    "        print(msg)\n",
    "#         self.log_list_.append(msg)\n",
    "        raise Exception\n",
    "\n",
    "    return bbox, label, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자동화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "account_name = \"katemeets\"\n",
    "expected_num_col = 5 # n_cluster 지정\n",
    "\n",
    "img_loc = glob(\"../Trip_Fashion_Recommend/data/pictures_{}/*\".format(account_name))\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4 \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "model = \"pspnet50_ade20k\"\n",
    "\n",
    "begin_time = time.time()\n",
    "\n",
    "with sess.as_default():\n",
    "    pspnet = PSPNet50(nb_classes=150, input_shape=(473, 473),\n",
    "                              weights=model)\n",
    "    lb_dict = {}\n",
    "    for i, img_path in enumerate(img_loc[15:]):\n",
    "            print(\"Processing image {} / {}\".format(i + 1, len(img_loc)))\n",
    "            img = imread(img_path, pilmode=\"RGB\")\n",
    "\n",
    "            probs = pspnet.predict_multi_scale(img, flip_evaluation=True, sliding_evaluation = True,  scales=[1.0])\n",
    "\n",
    "            cm = np.argmax(probs, axis=2)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # 원본 사진에서 bbox 도출\n",
    "            try:\n",
    "                bbox, label, conf = detect_person(img, i, img_path)\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                msg = '>>> Error in {}th file : {}\\n'.format(i+1, img_path)\n",
    "                print(msg)\n",
    "            \n",
    "            # Segmentation 처리가 된 이미지에서 bbox에 해당하는 부분만 cropping\n",
    "            xx = cm[bbox[0][1]:bbox[0][3], bbox[0][0]:bbox[0][2]]\n",
    "            unique_elements, counts_elements = np.unique(xx, return_counts=True)\n",
    "            unique_elements[np.where(counts_elements==max(counts_elements))][0]\n",
    "            a,b = np.where(xx == unique_elements[np.where(counts_elements==max(counts_elements))][0])\n",
    "            img_crop = img[bbox[0][1]:bbox[0][3], bbox[0][0]:bbox[0][2]]\n",
    "            \n",
    "            # Extract labels & cluster_centers_ by using KMeans\n",
    "            clt = KMeans(n_clusters = expected_num_col)\n",
    "            clt.fit(img_crop[a,b])\n",
    "            lb_counts = Counter(clt.labels_)\n",
    "            \n",
    "            tmp_dict = {}\n",
    "            filename = img_path.split('/')[-1]\n",
    "            for idx, pixel in enumerate(clt.cluster_centers_):\n",
    "                tmp_dict[ str(lb_counts[idx]) ] = pixel.tolist()  # { frequency of label : color of label } mapping\n",
    "                lb_dict[filename] = tmp_dict\n",
    "                pass\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    # json 파일에 lb_count , clt.cluster_centers_ 저장\n",
    "    save_path = \"../data/{}.json\".format(account_name)\n",
    "    with open(save_path, 'w') as json_file:\n",
    "        json.dump(lb_dict, json_file)\n",
    "\n",
    "end_time = time.time()\n",
    "  \n",
    "print('time elapsed while training : {}'.format(end_time - begin_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
